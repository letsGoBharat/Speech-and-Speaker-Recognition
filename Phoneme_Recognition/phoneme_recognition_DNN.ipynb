{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from proto import mfcc, mspec\n",
    "from proto2 import concatHMMs, log_multivariate_normal_density_diag, viterbi\n",
    "from prondict import prondict\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, utils, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab3_proto.py\n",
    "\n",
    "def words2phones(wordList, pronDict, addSilence=True, addShortPause=True):\n",
    "    \"\"\" word2phones: converts word level to phone level transcription adding silence\n",
    "\n",
    "    Args:\n",
    "       wordList: list of word symbols\n",
    "       pronDict: pronunciation dictionary. The keys correspond to words in wordList\n",
    "       addSilence: if True, add initial and final silence\n",
    "       addShortPause: if True, add short pause model \"sp\" at end of each word\n",
    "    Output:\n",
    "       list of phone symbols\n",
    "    \"\"\"\n",
    "    phone_list = []\n",
    "    if addSilence:\n",
    "        phone_list.append('sil')\n",
    "    for symbol in wordList:\n",
    "        for item in pronDict[symbol]:\n",
    "            phone_list.append(item)\n",
    "        phone_list.append('sp')\n",
    "    if addSilence:\n",
    "        phone_list.append('sil')\n",
    "    return list(phone_list)\n",
    "\n",
    "def forcedAlignment(lmfcc, phoneHMMs, phoneTrans):\n",
    "    \"\"\" forcedAlignmen: aligns a phonetic transcription at the state level\n",
    "\n",
    "    Args:\n",
    "       lmfcc: NxD array of MFCC feature vectors (N vectors of dimension D)\n",
    "              computed the same way as for the training of phoneHMMs\n",
    "       phoneHMMs: set of phonetic Gaussian HMM models\n",
    "       phoneTrans: list of phonetic symbols to be aligned including initial and\n",
    "                   final silence\n",
    "\n",
    "    Returns:\n",
    "       list of strings in the form phoneme_index specifying, for each time step\n",
    "       the state from phoneHMMs corresponding to the viterbi path.\n",
    "    \"\"\"\n",
    "\n",
    "def hmmLoop(hmmmodels, namelist=None):\n",
    "    \"\"\" Combines HMM models in a loop\n",
    "\n",
    "    Args:\n",
    "       hmmmodels: list of dictionaries with the following keys:\n",
    "           name: phonetic or word symbol corresponding to the model\n",
    "           startprob: M+1 array with priori probability of state\n",
    "           transmat: (M+1)x(M+1) transition matrix\n",
    "           means: MxD array of mean vectors\n",
    "           covars: MxD array of variances\n",
    "       namelist: list of model names that we want to combine, if None,\n",
    "                 all the models in hmmmodels are used\n",
    "\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be\n",
    "      different in each model)\n",
    "\n",
    "    Output\n",
    "       combinedhmm: dictionary with the same keys as the input but\n",
    "                    combined models\n",
    "       stateMap: map between states in combinedhmm and states in the\n",
    "                 input models.\n",
    "\n",
    "    Examples:\n",
    "       phoneLoop = hmmLoop(phoneHMMs)\n",
    "       wordLoop = hmmLoop(wordHMMs, ['o', 'z', '1', '2', '3'])\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab3_tools.py\n",
    "def path2info(path):\n",
    "    \"\"\"\n",
    "    path2info: parses paths in the TIDIGIT format and extracts information\n",
    "               about the speaker and the utterance\n",
    "\n",
    "    Example:\n",
    "    path2info('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')\n",
    "    \"\"\"\n",
    "    rest, filename = os.path.split(path)\n",
    "    rest, speakerID = os.path.split(rest)\n",
    "    rest, gender = os.path.split(rest)\n",
    "    digits = filename[:-5]\n",
    "    repetition = filename[-5]\n",
    "    return gender, speakerID, digits, repetition\n",
    "\n",
    "def loadAudio(filename):\n",
    "    \"\"\"\n",
    "    loadAudio: loads audio data from file using pysndfile\n",
    "\n",
    "    Note that, by default pysndfile converts the samples into floating point\n",
    "    numbers and rescales them in the range [-1, 1]. This is avoided by specifying\n",
    "    the option dtype=np.int16 which keeps both the original data type and range\n",
    "    of values.\n",
    "    \"\"\"\n",
    "    return sf.read(filename, dtype='int16')\n",
    "\n",
    "def frames2trans(sequence, outfilename=None, timestep=0.01):\n",
    "    \"\"\"\n",
    "    Outputs a standard transcription given a frame-by-frame\n",
    "    list of strings.\n",
    "\n",
    "    Example (using functions from Lab 1 and Lab 2):\n",
    "    phones = ['sil', 'sil', 'sil', 'ow', 'ow', 'ow', 'ow', 'ow', 'sil', 'sil']\n",
    "    trans = frames2trans(phones, 'oa.lab')\n",
    "\n",
    "    Then you can use, for example wavesurfer to open the wav file and the transcription\n",
    "    \"\"\"\n",
    "    sym = sequence[0]\n",
    "    start = 0\n",
    "    end = 0\n",
    "    trans = ''\n",
    "    for t in range(len(sequence)):\n",
    "        if sequence[t] != sym:\n",
    "            trans = trans + str(start) + ' ' + str(end) + ' ' + sym + '\\n'\n",
    "            sym = sequence[t]\n",
    "            start = end\n",
    "        end = end + timestep\n",
    "    trans = trans + str(start) + ' ' + str(end) + ' ' + sym + '\\n'\n",
    "    if outfilename != None:\n",
    "        with open(outfilename, 'w') as f:\n",
    "            f.write(trans)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('man', 'ae', 'z9z6531', 'a')\n",
      "(array([11, 13, 11, ...,  9,  9,  9], dtype=int16), 20000)\n"
     ]
    }
   ],
   "source": [
    "print(path2info('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav'))\n",
    "print(loadAudio('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav'))\n",
    "\n",
    "phoneHMMs = np.load('lab2_models_all.npz', allow_pickle = True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using python file i/o\n",
    "# f = open('phoneHmms_states.txt', 'w')\n",
    "# for state in stateList:\n",
    "#     f.write(state)\n",
    "# f.close()\n",
    "\n",
    "#using pandas df\n",
    "df = pd.DataFrame(stateList)\n",
    "df.to_csv('phoneHmms_states.csv', header=False, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z', '4', '3']\n",
      "['sil', 'z', 'iy', 'r', 'ow', 'sp', 'f', 'ao', 'r', 'sp', 'th', 'r', 'iy', 'sp', 'sil']\n",
      "\n",
      "['sil_0', 'sil_1', 'sil_2', 'z_0', 'z_1', 'z_2', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'sp_0', 'f_0', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_2', 'r_0', 'r_1', 'r_2', 'sp_0', 'th_0', 'th_1', 'th_2', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_1', 'iy_2', 'sp_0', 'sil_0', 'sil_1', 'sil_2']\n",
      "\n",
      "61\n",
      "['sil_0', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_2', 'z_0', 'z_0', 'z_0', 'z_0', 'z_1', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'f_0', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_1', 'th_1', 'th_1', 'th_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_1', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0']\n",
      "[39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 58, 58, 58, 58, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 21, 21, 21, 21, 21, 21, 21, 21, 22, 23, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 35, 30, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 33, 33, 33, 34, 35, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 48, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 35, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39]\n",
      "0 0.01 sil_0\n",
      "0.01 0.19000000000000003 sil_1\n",
      "0.19000000000000003 0.20000000000000004 sil_2\n",
      "0.20000000000000004 0.24000000000000007 z_0\n",
      "0.24000000000000007 0.25000000000000006 z_1\n",
      "0.25000000000000006 0.36000000000000015 z_2\n",
      "0.36000000000000015 0.4400000000000002 iy_0\n",
      "0.4400000000000002 0.45000000000000023 iy_1\n",
      "0.45000000000000023 0.46000000000000024 iy_2\n",
      "0.46000000000000024 0.5600000000000003 r_0\n",
      "0.5600000000000003 0.5700000000000003 r_1\n",
      "0.5700000000000003 0.5800000000000003 r_2\n",
      "0.5800000000000003 0.5900000000000003 ow_0\n",
      "0.5900000000000003 0.6000000000000003 ow_1\n",
      "0.6000000000000003 0.6900000000000004 ow_2\n",
      "0.6900000000000004 0.7000000000000004 f_0\n",
      "0.7000000000000004 0.8100000000000005 f_1\n",
      "0.8100000000000005 0.8200000000000005 f_2\n",
      "0.8200000000000005 0.8300000000000005 ao_0\n",
      "0.8300000000000005 0.9700000000000006 ao_1\n",
      "0.9700000000000006 1.0800000000000007 ao_2\n",
      "1.0800000000000007 1.1100000000000008 r_0\n",
      "1.1100000000000008 1.1200000000000008 r_1\n",
      "1.1200000000000008 1.1300000000000008 r_2\n",
      "1.1300000000000008 1.2300000000000009 th_0\n",
      "1.2300000000000009 1.260000000000001 th_1\n",
      "1.260000000000001 1.270000000000001 th_2\n",
      "1.270000000000001 1.360000000000001 r_0\n",
      "1.360000000000001 1.370000000000001 r_1\n",
      "1.370000000000001 1.380000000000001 r_2\n",
      "1.380000000000001 1.480000000000001 iy_0\n",
      "1.480000000000001 1.500000000000001 iy_1\n",
      "1.500000000000001 1.5800000000000012 iy_2\n",
      "1.5800000000000012 1.7800000000000014 sil_0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "#For 1 File - 4.1 - 4.2\n",
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)\n",
    "lmfcc = mfcc(samples)\n",
    "wordTrans = list(path2info(filename)[2])\n",
    "print(wordTrans)\n",
    "phoneTrans = words2phones(wordTrans, prondict)\n",
    "print(phoneTrans)\n",
    "print()\n",
    "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
    "#print(utteranceHMM)\n",
    "\n",
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\n",
    "print(stateTrans)\n",
    "print()\n",
    "\n",
    "\n",
    "viterbi_loglik, viterbi_states = viterbi(log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'],\n",
    "                      utteranceHMM['covars']), np.log(utteranceHMM['startprob']),\n",
    "                      np.log(utteranceHMM['transmat']), True)\n",
    "\n",
    "state_list = pd.read_csv('phoneHmms_states.csv', header = None)\n",
    "state_list = state_list[0].to_list()\n",
    "print(len(state_list))\n",
    "\n",
    "viterbiStateTrans = [stateTrans[state] for state in viterbi_states]\n",
    "print(viterbiStateTrans)\n",
    "\n",
    "targets = [state_list.index(state) for state in viterbiStateTrans]\n",
    "print(targets)\n",
    "\n",
    "\n",
    "trans = frames2trans(viterbiStateTrans, outfilename='z43a.lab') #wavesurfer not working on my machine..need to verify this part!\n",
    "print(trans)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all files - 4.3\n",
    "def feature_extraction(samples):\n",
    "    lmfcc = mfcc(samples)\n",
    "    mspec_all = mspec(samples)\n",
    "    return lmfcc, mspec_all\n",
    "\n",
    "def forced_alignment(filename, phone_HMMs, pron_dict):\n",
    "    wordTrans = list(path2info(filename)[2])\n",
    "    phoneTrans = words2phones(wordTrans, pron_dict)\n",
    "    utteranceHMM = concatHMMs(phone_HMMs, phoneTrans)\n",
    "    stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\n",
    "    return utteranceHMM, stateTrans\n",
    "\n",
    "def create_train_data(train_fpath, phone_HMMs, pron_dict, state_list):\n",
    "    traindata = []\n",
    "    for root, dirs, files in os.walk(train_fpath):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filename = os.path.join(root, file)\n",
    "                samples, samplingrate = loadAudio(filename)\n",
    "                lmfcc, mspec_all = feature_extraction(samples)\n",
    "                utteranceHMM, stateTrans = forced_alignment(filename, phone_HMMs, pron_dict)\n",
    "                _, viterbi_states = viterbi(log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'],\n",
    "                          utteranceHMM['covars']), np.log(utteranceHMM['startprob']),\n",
    "                          np.log(utteranceHMM['transmat']), True)\n",
    "                viterbiStateTrans = [stateTrans[state] for state in viterbi_states]\n",
    "                targets = [state_list.index(state) for state in viterbiStateTrans]\n",
    "                traindata.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': mspec_all, 'targets': targets})\n",
    "    return traindata\n",
    "                \n",
    "def create_test_data(test_path, phone_HMMs, pron_dict, state_list):\n",
    "    testdata = []\n",
    "    for root, dirs, files in os.walk(test_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filename = os.path.join(root, file)\n",
    "                samples, samplingrate = loadAudio(filename)\n",
    "                lmfcc, mspec_all = feature_extraction(samples)\n",
    "                utteranceHMM, stateTrans = forced_alignment(filename, phone_HMMs, pron_dict)\n",
    "                _, viterbi_states = viterbi(log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'],\n",
    "                          utteranceHMM['covars']), np.log(utteranceHMM['startprob']),\n",
    "                          np.log(utteranceHMM['transmat']), True)\n",
    "                viterbiStateTrans = [stateTrans[state] for state in viterbi_states]\n",
    "                targets = [state_list.index(state) for state in viterbiStateTrans]\n",
    "                testdata.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': mspec_all, 'targets': targets})\n",
    "    return testdata\n",
    "\n",
    "def split_data(train_fpath):    \n",
    "    traindata = np.load(train_fpath, allow_pickle=True)\n",
    "    traindata = traindata['data']\n",
    "\n",
    "    samples = len(traindata)\n",
    "    val_size = int(0.1 * samples)\n",
    "    print(val_size)\n",
    "    val_n_speakers = int(val_size / 77) #Why 77?\n",
    "\n",
    "    if val_n_speakers % 2 != 0:\n",
    "        val_n_speakers += 1\n",
    "\n",
    "    val_size = val_n_speakers * 77\n",
    "    print(val_size)\n",
    "    samples_gender = int(val_size / 2)\n",
    "\n",
    "    valdata = [traindata[i] for i in range(0, samples_gender)]\n",
    "    valdata.extend([traindata[i] for i in range(4235, 4235 + samples_gender)])\n",
    "    trainingdata = [sample for sample in traindata if sample['filename'] not in [x['filename'] for x in valdata]]\n",
    "\n",
    "    #np.savez('trainingdata.npz', data=trainingdata)\n",
    "    #np.savez('valdata.npz', data=valdata)\n",
    "\n",
    "    return\n",
    "\n",
    "def dynamic_features(data_fpath):\n",
    "    data = np.load(data_fpath, allow_pickle=True)\n",
    "    data = data['data']\n",
    "\n",
    "    for sample in data:\n",
    "        dfeature_list = []\n",
    "        i_max = len(sample['lmfcc']) - 1\n",
    "        for i, feature in enumerate(sample['lmfcc']):\n",
    "            dfeature = np.zeros((7, feature.shape[0]))\n",
    "\n",
    "            dfeature[0] = sample['lmfcc'][np.abs(i - 3)]\n",
    "            dfeature[1] = sample['lmfcc'][np.abs(i - 2)]\n",
    "            dfeature[2] = sample['lmfcc'][np.abs(i - 1)]\n",
    "            dfeature[3] = sample['lmfcc'][i]\n",
    "            dfeature[4] = sample['lmfcc'][i_max - np.abs(i_max - (i + 1))]\n",
    "            dfeature[5] = sample['lmfcc'][i_max - np.abs(i_max - (i + 2))]\n",
    "            dfeature[6] = sample['lmfcc'][i_max - np.abs(i_max - (i + 3))]\n",
    "            dfeature_list.append(dfeature)\n",
    "        sample['features'] = np.array(dfeature_list)\n",
    "\n",
    "    s = data_fpath.split('/')\n",
    "    np.savez('d' + s[-1], data = data)\n",
    "\n",
    "    return\n",
    "    \n",
    "def feature_std(dtrainfpath, dvalfpath, dtestfpath):\n",
    "    paths = [dtrainfpath, dvalfpath. dtestfpath]\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for p in paths:\n",
    "        ddata = np.load(p)\n",
    "\n",
    "        N = 0\n",
    "        D = np.prod(np.array(ddata[0]['features']).shape[1:3])\n",
    "        for sample in ddata:\n",
    "            N += sample['features'].shape[0]\n",
    "\n",
    "        X = np.zeros((N, D))\n",
    "        y = np.zeros((N, 1))\n",
    "        prev_idx = 0\n",
    "        for sample in ddata:\n",
    "            dynamic_features = np.array(sample['features'])\n",
    "            n = dynamic_features.shape[0]\n",
    "            X[prev_idx:prev_idx + n] = dynamic_features.reshape((n, D))\n",
    "            y[prev_idx:prev_idx + n, 0] = sample['targets']\n",
    "            prev_idx += n\n",
    "        Xs.append(X)\n",
    "        ys.append(y)\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(Xs[0])\n",
    "    sets = ['train', 'val', 'test']\n",
    "    for i, s in enumerate(sets):\n",
    "        Xs[i] = scaler.transform(Xs[i])\n",
    "        Xs[i] = Xs[i].astype('float32')\n",
    "        print(Xs[i].shape)\n",
    "        np.savez('X_' + s + '.npz', X=Xs[i])\n",
    "        np.savez('y_' + s + '.npz', X=Xs[i])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862\n",
      "924\n"
     ]
    }
   ],
   "source": [
    "#train_path = 'tidigits/disc_4.1.1/tidigits/train'\n",
    "#traindata = create_train_data(train_path, phoneHMMs, prondict, state_list)\n",
    "#\n",
    "#test_path = 'tidigits/disc_4.2.1/tidigits/test'\n",
    "#testdata = create_test_data(test_path, phoneHMMs, prondict, state_list)\n",
    "#\n",
    "#np.savez('traindata.npz', data=traindata)\n",
    "#np.savez('testdata.npz', data=testdata)\n",
    "#\n",
    "split_data('traindata.npz')\n",
    "#dynamic_features('trainingdata.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for training the model(without dynamic features)\n",
    "input_type = 'mfcc'\n",
    "\n",
    "training_data = np.load('trainingdata.npz', allow_pickle = 'True')\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for train_data in training_data['data']:\n",
    "    if input_type = 'mfcc':\n",
    "        X_train.append(train_data['lmfcc'])\n",
    "    elif input_type = 'mspec':\n",
    "        X_train.append(train_data['mspec'])\n",
    "    Y_train.append(train_data['targets'])\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "\n",
    "validation_data = np.load('valdata.npz', allow_pickle = 'True')\n",
    "X_val = []\n",
    "Y_val = []\n",
    "for val_data in training_data['data']:\n",
    "    if input_type = 'mfcc':\n",
    "        X_val.append(val_data['lmfcc'])\n",
    "    elif input_type = 'mspec':\n",
    "        X_val.append(val_data['mspec'])\n",
    "    Y_train.append(val_data['targets'])\n",
    "X_val = np.asarray(X_val)\n",
    "Y_val = np.asarray(Y_val)\n",
    "\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_val = tf.keras.utils.to_categorical(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN model\n",
    "if input_type = 'mfcc':\n",
    "    f_count = 13\n",
    "elif input_type = 'mspec':\n",
    "    f_count = 40\n",
    "output_classes = 61 #Number of states in state list\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, input_shape=(f_count,), activation = 'relu'))\n",
    "model.add(layers.Dense(output_classes, actiavtion = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), batch_size = 256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
