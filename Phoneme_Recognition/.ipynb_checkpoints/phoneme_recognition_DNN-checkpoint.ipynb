{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from proto import mfcc, mspec\n",
    "from proto2 import concatHMMs, log_multivariate_normal_density_diag, viterbi\n",
    "from prondict import prondict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab3_proto.py\n",
    "\n",
    "def words2phones(wordList, pronDict, addSilence=True, addShortPause=True):\n",
    "    \"\"\" word2phones: converts word level to phone level transcription adding silence\n",
    "\n",
    "    Args:\n",
    "       wordList: list of word symbols\n",
    "       pronDict: pronunciation dictionary. The keys correspond to words in wordList\n",
    "       addSilence: if True, add initial and final silence\n",
    "       addShortPause: if True, add short pause model \"sp\" at end of each word\n",
    "    Output:\n",
    "       list of phone symbols\n",
    "    \"\"\"\n",
    "    phone_list = []\n",
    "    if addSilence:\n",
    "        phone_list.append('sil')\n",
    "    for symbol in wordList:\n",
    "        for item in pronDict[symbol]:\n",
    "            phone_list.append(item)\n",
    "        phone_list.append('sp')\n",
    "    if addSilence:\n",
    "        phone_list.append('sil')\n",
    "    return list(phone_list)\n",
    "\n",
    "def forcedAlignment(lmfcc, phoneHMMs, phoneTrans):\n",
    "    \"\"\" forcedAlignmen: aligns a phonetic transcription at the state level\n",
    "\n",
    "    Args:\n",
    "       lmfcc: NxD array of MFCC feature vectors (N vectors of dimension D)\n",
    "              computed the same way as for the training of phoneHMMs\n",
    "       phoneHMMs: set of phonetic Gaussian HMM models\n",
    "       phoneTrans: list of phonetic symbols to be aligned including initial and\n",
    "                   final silence\n",
    "\n",
    "    Returns:\n",
    "       list of strings in the form phoneme_index specifying, for each time step\n",
    "       the state from phoneHMMs corresponding to the viterbi path.\n",
    "    \"\"\"\n",
    "\n",
    "def hmmLoop(hmmmodels, namelist=None):\n",
    "    \"\"\" Combines HMM models in a loop\n",
    "\n",
    "    Args:\n",
    "       hmmmodels: list of dictionaries with the following keys:\n",
    "           name: phonetic or word symbol corresponding to the model\n",
    "           startprob: M+1 array with priori probability of state\n",
    "           transmat: (M+1)x(M+1) transition matrix\n",
    "           means: MxD array of mean vectors\n",
    "           covars: MxD array of variances\n",
    "       namelist: list of model names that we want to combine, if None,\n",
    "                 all the models in hmmmodels are used\n",
    "\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be\n",
    "      different in each model)\n",
    "\n",
    "    Output\n",
    "       combinedhmm: dictionary with the same keys as the input but\n",
    "                    combined models\n",
    "       stateMap: map between states in combinedhmm and states in the\n",
    "                 input models.\n",
    "\n",
    "    Examples:\n",
    "       phoneLoop = hmmLoop(phoneHMMs)\n",
    "       wordLoop = hmmLoop(wordHMMs, ['o', 'z', '1', '2', '3'])\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def path2info(path):\n",
    "    \"\"\"\n",
    "    path2info: parses paths in the TIDIGIT format and extracts information\n",
    "               about the speaker and the utterance\n",
    "\n",
    "    Example:\n",
    "    path2info('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')\n",
    "    \"\"\"\n",
    "    rest, filename = os.path.split(path)\n",
    "    rest, speakerID = os.path.split(rest)\n",
    "    rest, gender = os.path.split(rest)\n",
    "    digits = filename[:-5]\n",
    "    repetition = filename[-5]\n",
    "    return gender, speakerID, digits, repetition\n",
    "\n",
    "def loadAudio(filename):\n",
    "    \"\"\"\n",
    "    loadAudio: loads audio data from file using pysndfile\n",
    "\n",
    "    Note that, by default pysndfile converts the samples into floating point\n",
    "    numbers and rescales them in the range [-1, 1]. This is avoided by specifying\n",
    "    the option dtype=np.int16 which keeps both the original data type and range\n",
    "    of values.\n",
    "    \"\"\"\n",
    "    return sf.read(filename, dtype='int16')\n",
    "\n",
    "def frames2trans(sequence, outfilename=None, timestep=0.01):\n",
    "    \"\"\"\n",
    "    Outputs a standard transcription given a frame-by-frame\n",
    "    list of strings.\n",
    "\n",
    "    Example (using functions from Lab 1 and Lab 2):\n",
    "    phones = ['sil', 'sil', 'sil', 'ow', 'ow', 'ow', 'ow', 'ow', 'sil', 'sil']\n",
    "    trans = frames2trans(phones, 'oa.lab')\n",
    "\n",
    "    Then you can use, for example wavesurfer to open the wav file and the transcription\n",
    "    \"\"\"\n",
    "    sym = sequence[0]\n",
    "    start = 0\n",
    "    end = 0\n",
    "    trans = ''\n",
    "    for t in range(len(sequence)):\n",
    "        if sequence[t] != sym:\n",
    "            trans = trans + str(start) + ' ' + str(end) + ' ' + sym + '\\n'\n",
    "            sym = sequence[t]\n",
    "            start = end\n",
    "        end = end + timestep\n",
    "    trans = trans + str(start) + ' ' + str(end) + ' ' + sym + '\\n'\n",
    "    if outfilename != None:\n",
    "        with open(outfilename, 'w') as f:\n",
    "            f.write(trans)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('man', 'ae', 'z9z6531', 'a')\n",
      "(array([11, 13, 11, ...,  9,  9,  9], dtype=int16), 20000)\n"
     ]
    }
   ],
   "source": [
    "print(path2info('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav'))\n",
    "print(loadAudio('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav'))\n",
    "\n",
    "phoneHMMs = np.load('lab2_models_all.npz', allow_pickle = True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using python file i/o\n",
    "# f = open('phoneHmms_states.txt', 'w')\n",
    "# for state in stateList:\n",
    "#     f.write(state)\n",
    "# f.close()\n",
    "\n",
    "#using pandas df\n",
    "df = pd.DataFrame(stateList)\n",
    "df.to_csv('phoneHmms_states.csv', header=False, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z', '4', '3']\n",
      "['sil', 'z', 'iy', 'r', 'ow', 'sp', 'f', 'ao', 'r', 'sp', 'th', 'r', 'iy', 'sp', 'sil']\n",
      "\n",
      "['sil_0', 'sil_1', 'sil_2', 'z_0', 'z_1', 'z_2', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'sp_0', 'f_0', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_2', 'r_0', 'r_1', 'r_2', 'sp_0', 'th_0', 'th_1', 'th_2', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_1', 'iy_2', 'sp_0', 'sil_0', 'sil_1', 'sil_2']\n",
      "\n",
      "['ah_0', 'ah_1', 'ah_2', 'ao_0', 'ao_1', 'ao_2', 'ay_0', 'ay_1', 'ay_2', 'eh_0', 'eh_1', 'eh_2', 'ey_0', 'ey_1', 'ey_2', 'f_0', 'f_1', 'f_2', 'ih_0', 'ih_1', 'ih_2', 'iy_0', 'iy_1', 'iy_2', 'k_0', 'k_1', 'k_2', 'n_0', 'n_1', 'n_2', 'ow_0', 'ow_1', 'ow_2', 'r_0', 'r_1', 'r_2', 's_0', 's_1', 's_2', 'sil_0', 'sil_1', 'sil_2', 'sp_0', 't_0', 't_1', 't_2', 'th_0', 'th_1', 'th_2', 'uw_0', 'uw_1', 'uw_2', 'v_0', 'v_1', 'v_2', 'w_0', 'w_1', 'w_2', 'z_0', 'z_1', 'z_2']\n",
      "['sil_0', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_2', 'z_0', 'z_0', 'z_0', 'z_0', 'z_1', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'f_0', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_1', 'th_1', 'th_1', 'th_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_1', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0']\n",
      "[39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 58, 58, 58, 58, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 21, 21, 21, 21, 21, 21, 21, 21, 22, 23, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 35, 30, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 33, 33, 33, 34, 35, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 48, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 35, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39]\n",
      "0 0.01 sil_0\n",
      "0.01 0.19000000000000003 sil_1\n",
      "0.19000000000000003 0.20000000000000004 sil_2\n",
      "0.20000000000000004 0.24000000000000007 z_0\n",
      "0.24000000000000007 0.25000000000000006 z_1\n",
      "0.25000000000000006 0.36000000000000015 z_2\n",
      "0.36000000000000015 0.4400000000000002 iy_0\n",
      "0.4400000000000002 0.45000000000000023 iy_1\n",
      "0.45000000000000023 0.46000000000000024 iy_2\n",
      "0.46000000000000024 0.5600000000000003 r_0\n",
      "0.5600000000000003 0.5700000000000003 r_1\n",
      "0.5700000000000003 0.5800000000000003 r_2\n",
      "0.5800000000000003 0.5900000000000003 ow_0\n",
      "0.5900000000000003 0.6000000000000003 ow_1\n",
      "0.6000000000000003 0.6900000000000004 ow_2\n",
      "0.6900000000000004 0.7000000000000004 f_0\n",
      "0.7000000000000004 0.8100000000000005 f_1\n",
      "0.8100000000000005 0.8200000000000005 f_2\n",
      "0.8200000000000005 0.8300000000000005 ao_0\n",
      "0.8300000000000005 0.9700000000000006 ao_1\n",
      "0.9700000000000006 1.0800000000000007 ao_2\n",
      "1.0800000000000007 1.1100000000000008 r_0\n",
      "1.1100000000000008 1.1200000000000008 r_1\n",
      "1.1200000000000008 1.1300000000000008 r_2\n",
      "1.1300000000000008 1.2300000000000009 th_0\n",
      "1.2300000000000009 1.260000000000001 th_1\n",
      "1.260000000000001 1.270000000000001 th_2\n",
      "1.270000000000001 1.360000000000001 r_0\n",
      "1.360000000000001 1.370000000000001 r_1\n",
      "1.370000000000001 1.380000000000001 r_2\n",
      "1.380000000000001 1.480000000000001 iy_0\n",
      "1.480000000000001 1.500000000000001 iy_1\n",
      "1.500000000000001 1.5800000000000012 iy_2\n",
      "1.5800000000000012 1.7800000000000014 sil_0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "#For 1 File - 4.1 - 4.2\n",
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)\n",
    "lmfcc = mfcc(samples)\n",
    "wordTrans = list(path2info(filename)[2])\n",
    "print(wordTrans)\n",
    "phoneTrans = words2phones(wordTrans, prondict)\n",
    "print(phoneTrans)\n",
    "print()\n",
    "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
    "#print(utteranceHMM)\n",
    "\n",
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\n",
    "print(stateTrans)\n",
    "print()\n",
    "\n",
    "\n",
    "viterbi_loglik, viterbi_states = viterbi(log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'],\n",
    "                      utteranceHMM['covars']), np.log(utteranceHMM['startprob']),\n",
    "                      np.log(utteranceHMM['transmat']), True)\n",
    "\n",
    "state_list = pd.read_csv('phoneHmms_states.csv', header = None)\n",
    "state_list = state_list[0].to_list()\n",
    "print(state_list)\n",
    "\n",
    "viterbiStateTrans = [stateTrans[state] for state in viterbi_states]\n",
    "print(viterbiStateTrans)\n",
    "\n",
    "targets = [state_list.index(state) for state in viterbiStateTrans]\n",
    "print(targets)\n",
    "\n",
    "\n",
    "trans = frames2trans(viterbiStateTrans, outfilename='z43a.lab') #wavesurfer not working on my machine..need to verify this part!\n",
    "print(trans)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all files - 4.3\n",
    "def feature_extraction(samples):\n",
    "    lmfcc = mfcc(samples)\n",
    "    mspec_all = mspec(samples)\n",
    "    return lmfcc, mspec_all\n",
    "\n",
    "def forced_alignment(filename, phoneHMMs, pron_dict):\n",
    "    wordTrans = list(path2info(filename)[2])\n",
    "    phoneTrans = words2phones(wordTrans, pron_dict)\n",
    "    utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
    "    stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\n",
    "    return utteranceHMM, stateTrans\n",
    "\n",
    "def create_train_data():\n",
    "    traindata = []\n",
    "    for root, dirs, files in os.walk('tidigits/disc_4.1.1/tidigits/train'):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filename = os.path.join(root, file)\n",
    "                samples, samplingrate = loadAudio(filename)\n",
    "                lmfcc, mspec_all = feature_extraction(samples)\n",
    "                utteranceHMM, stateTrans = forced_alignment(filename, phoneHMMs, prondict)\n",
    "                _, viterbi_states = viterbi(log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'],\n",
    "                          utteranceHMM['covars']), np.log(utteranceHMM['startprob']),\n",
    "                          np.log(utteranceHMM['transmat']), True)\n",
    "                viterbiStateTrans = [stateTrans[state] for state in viterbi_states]\n",
    "                targets = [state_list.index(state) for state in viterbiStateTrans]\n",
    "                traindata.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': mspec_all, 'targets': targets})\n",
    "                \n",
    "def create_test_data():\n",
    "    testdata = []\n",
    "    for root, dirs, files in os.walk('tidigits/disc_4.1.1/tidigits/test'):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filename = os.path.join(root, file)\n",
    "                samples, samplingrate = loadAudio(filename)\n",
    "                lmfcc, mspec_all = feature_extraction(samples)\n",
    "                utteranceHMM, stateTrans = forced_alignment(filename, phoneHMMs, prondict)\n",
    "                _, viterbi_states = viterbi(log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'],\n",
    "                          utteranceHMM['covars']), np.log(utteranceHMM['startprob']),\n",
    "                          np.log(utteranceHMM['transmat']), True)\n",
    "                viterbiStateTrans = [stateTrans[state] for state in viterbi_states]\n",
    "                targets = [state_list.index(state) for state in viterbiStateTrans]\n",
    "                testdata.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': mspec_all, 'targets': targets})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-5d7a6561c3e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             _, viterbi_states = viterbi(log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'],\n\u001b[1;32m     12\u001b[0m                       utteranceHMM['covars']), np.log(utteranceHMM['startprob']),\n\u001b[0;32m---> 13\u001b[0;31m                       np.log(utteranceHMM['transmat']), True)\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mviterbiStateTrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstateTrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mviterbi_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/KTH_Academics/Second_Term/Speaker and Speech Recognition/workspace/Phoneme_Recognition/proto2.py\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(log_emlik, log_startprob, log_transmat, forceFinalState)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memissions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_transmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_emlik\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_transmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2619\u001b[0m     \"\"\"\n\u001b[1;32m   2620\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2621\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.savez('traindata.npz', traindata=traindata)\n",
    "np.savez('testdata.npz', testdata=testdata)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
